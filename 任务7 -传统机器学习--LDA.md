1. pLSA、共轭先验分布；LDA主题模型原理  
    我们可以看看日常生活中人是如何构思文章的。如果我们要写一篇文章，往往是先确定要写哪几个主题。  
    譬如构思一篇自然语言处理相关的文章，可能 40\% 会谈论语言学、30\% 谈论概率统计、20\% 谈论计算机、  
    还有10\%谈论其它的主题：说到语言学，我们容易想到的词包括：语法、句子、乔姆斯基、句法分析、主语…；  
    谈论概率统计，我们容易想到以下一些词: 概率、模型、均值、方差、证明、独立、马尔科夫链、…；  
    谈论计算机，我们容易想到的词是： 内存、硬盘、编程、二进制、对象、算法、复杂度…；  
    我们之所以能马上想到这些词，是因为这些词在对应的主题下出现的概率很高。我们可以很自然的看到，  
    一篇文章通常是由多个主题构成的、而每一个主题大概可以用与该主题相关的频率最高的一些词来描述。  
    ![img](https://github.com/lbj000/nlp/blob/master/game-plsa.jpg)  
    ![img](https://github.com/lbj000/nlp/blob/master/plsa-doc-topic-word.jpg)  
2. LDA应用场景   
3. LDA优缺点   
4. LDA 参数学习   
5. 使用LDA生成主题特征，在之前特征的基础上加入主题特征进行文本分类  
